═══════════════════════════════════════════════════════
  🚀 FPGA FAE 助手 - 快速开始
═══════════════════════════════════════════════════════

📅 更新时间: 2026-02-06
🎯 目标: 3 步启动应用

───────────────────────────────────────────────────────
  第 1 步: 安装依赖
───────────────────────────────────────────────────────

npm install

⏱️ 预计耗时: 2-3 分钟

───────────────────────────────────────────────────────
  第 2 步: 配置环境变量
───────────────────────────────────────────────────────

1. 复制环境变量模板:
   cp .env.example .env

2. 编辑 .env 文件，选择以下方案之一:

方案 A: 使用 Ollama 本地模型（免费）
────────────────────────────────────
AI_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

✅ 优点: 完全免费，数据隐私
❌ 要求: 需要先安装 Ollama
📥 下载: https://ollama.ai

安装 Ollama 后运行:
ollama pull llama3.1:8b

方案 B: 使用 Claude API（付费，效果更好）
────────────────────────────────────
AI_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-api03-你的密钥
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

✅ 优点: 效果最好，响应快
❌ 要求: 需要付费 API 密钥
📥 获取: https://console.anthropic.com/

───────────────────────────────────────────────────────
  第 3 步: 启动应用
───────────────────────────────────────────────────────

npm run dev

🎉 完成！访问: http://localhost:3000

───────────────────────────────────────────────────────
  使用指南
───────────────────────────────────────────────────────

1. 上传 PDF 文档
   - 点击侧边栏"文档库"
   - 上传 FPGA 数据手册（最大 10MB）

2. 与 AI 对话
   - 在输入框输入问题
   - AI 会自动检索文档内容回答

3. 示例问题
   - "Xilinx 7 系列 FPGA 的时钟资源有哪些？"
   - "如何配置 FPGA 的 I/O 标准？"
   - "FPGA 设计中如何优化时序？"

───────────────────────────────────────────────────────
  常见问题
───────────────────────────────────────────────────────

Q: 端口被占用怎么办？
A: PORT=3001 npm run dev

Q: Ollama 连接失败？
A: 确保 Ollama 服务正在运行
   检查: curl http://localhost:11434

Q: Claude API 调用失败？
A: 检查 API 密钥格式是否正确
   格式: sk-ant-api03-xxxxx...

Q: 如何切换模型？
A: 修改 .env 中的 AI_PROVIDER 变量

───────────────────────────────────────────────────────
  健康检查
───────────────────────────────────────────────────────

访问: http://localhost:3000/api/health

正常返回:
{
  "status": "healthy",
  "provider": "ollama",
  "model": "llama3.1:8b"
}

───────────────────────────────────────────────────────
  更多信息
───────────────────────────────────────────────────────

📖 完整文档: README.md
🐛 问题排查: 查看浏览器控制台和服务器日志
💬 获取帮助: 提交 GitHub Issue

═══════════════════════════════════════════════════════
Made with ❤️ for FPGA Engineers
═══════════════════════════════════════════════════════
